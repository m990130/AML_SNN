{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the conv\n",
    "* kernel size of time should be 1, otherwise it gets convolved as well.\n",
    "* bias=False\n",
    "* replace their pool layer with nn.AvgPool3d. The pool they used is a $sum*\\theta$ not an average.\n",
    "* should recieve the Spikes from the previous layer\n",
    "\n",
    "## Pipeline\n",
    "raw data(B,C,H,W) --- spike generation ---> spike(B,C,H,W,T) --- Conv3d on spikes ---> X(t) for every t of T --- eq 1: LIF, threshold and reset ---> intermediate V(t), the membrane potential --- based on V(t) ---> Spikes for the next layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 3 classes we should be able to use them directly\n",
    "## We need spikes from spike generatior as input and the spike counter, then they should work fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0,
     45,
     55,
     66,
     89
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def LIF(spikes, theta, leak, V_min):\n",
    "    \n",
    "#         '''\n",
    "#         Integrate-and-fire: given a tensor with shape (B,C,H,W,T), loop over T\n",
    "\n",
    "#         Params: \n",
    "#             spikes: the spikes from previous layer, containing 0 or 1.\n",
    "#             theta: threshold to fire a spike.\n",
    "#             l: leakage parameter.\n",
    "#             V_min: the resting state of membrane potential, usually is set to 0.\n",
    "\n",
    "#         return:\n",
    "#             V: the potential to fire (just for check, can be removed later)\n",
    "#             next_spikes: 0 or 1 tensor with the same shape of input\n",
    "\n",
    "#         '''\n",
    "        \n",
    "#         # the padding controls where to pad, first two of the tuple control the last dim of the tensor\n",
    "#         _pad = nn.ConstantPad3d((1,0,0,0,0,0), 0)\n",
    "#         pad_spikes = _pad(spikes)\n",
    "\n",
    "#         V = torch.zeros_like(pad_spikes)\n",
    "#         next_Spikes = torch.zeros_like(pad_spikes)\n",
    "\n",
    "#         T = pad_spikes.shape[-1]\n",
    "\n",
    "#         for t in range(1, T):\n",
    "#             # equation (1a)\n",
    "#             V[:,:,:,:,t] = V[:,:,:,:,t-1] + leak + pad_spikes[:,:,:,:,t]\n",
    "#             # thresholding and fire spike (1b)\n",
    "#             mask_threshold = V[:,:,:,:,t] >= theta\n",
    "#             next_Spikes[:,:,:,:,t][mask_threshold] = 1        \n",
    "#             # reset the potential to zero \n",
    "#             V[:,:,:,:,t][mask_threshold] = 0\n",
    "            \n",
    "#             # reset the value to V_min if drops below (1c)\n",
    "#             mask_min = (V[:,:,:,:,t] < V_min)\n",
    "#             V[:,:,:,:,t][mask_min] = V_min\n",
    "\n",
    "#         return (V[:,:,:,:,1:], next_Spikes[:,:,:,:,1:])\n",
    "\n",
    "\n",
    "\n",
    "# class convLayer(nn.Conv3d):\n",
    "\n",
    "#     def __init__(self, inChannels, outChannels, kernelSize, theta, leak=0, V_min=0):\n",
    "        \n",
    "#         kernel = (kernelSize, kernelSize, 1)\n",
    "        \n",
    "#         super(convLayer, self).__init__(inChannels, outChannels, kernel, bias=False)\n",
    "#         self.theta = theta\n",
    "#         self.leak = leak\n",
    "#         self.V_min = V_min\n",
    "\n",
    "        \n",
    "#     def forward(self, input):\n",
    "        \n",
    "#         # get X, namely eq(2)\n",
    "#         conv_spikes = F.conv3d(input, \n",
    "#                         self.weight, self.bias, \n",
    "#                         self.stride, self.padding, self.dilation, self.groups)\n",
    "        \n",
    "#         output = LIF(conv_spikes, self.theta, self.leak, self.V_min)\n",
    "        \n",
    "#         return (conv_spikes, *output)\n",
    "    \n",
    "# class poolLayer(nn.AvgPool3d):\n",
    "#     def __init__(self, kernelSize, theta, leak=0, V_min=0):\n",
    "        \n",
    "#         if type(kernelSize) == int:\n",
    "#             kernel_size = (kernelSize, kernelSize, 1)\n",
    "#         elif len(kernelSize) == 2:\n",
    "#             kernel_size = (kernelSize[0], kernelSize[1], 1)\n",
    "#         else:\n",
    "#             raise Exception('kernelSize can only be of 1 or 2 dimension. It was: {}'.format(kernelSize.shape))\n",
    "#         super(poolLayer, self).__init__(kernel_size)\n",
    "#         self.theta = theta\n",
    "#         self.leak = leak\n",
    "#         self.V_min = V_min\n",
    "        \n",
    "#     def forward(self, input):\n",
    "        \n",
    "#         # get X, namely eq(2)\n",
    "#         pool_spikes = F.avg_pool3d(input, self.kernel_size)\n",
    "        \n",
    "#         output = LIF(pool_spikes, self.theta, self.leak, self.V_min)\n",
    "        \n",
    "#         return (pool_spikes, *output)\n",
    "\n",
    "# class denseLayer(nn.Conv3d):\n",
    "#     def __init__(self, inFeatures, outFeatures, theta, leak=0, V_min=0):\n",
    "#         '''\n",
    "#         '''\n",
    "#         # extract information for kernel and inChannels\n",
    "#         if type(inFeatures) == int:\n",
    "#             kernel = (1, 1, 1)\n",
    "#             inChannels = inFeatures \n",
    "#         elif len(inFeatures) == 2:\n",
    "#             kernel = (inFeatures[1], inFeatures[0], 1)\n",
    "#             inChannels = 1\n",
    "#         elif len(inFeatures) == 3:\n",
    "#             kernel = (inFeatures[1], inFeatures[0], 1)\n",
    "#             inChannels = inFeatures[2]\n",
    "#         else:\n",
    "#             raise Exception('inFeatures should not be more than 3 dimension. It was: {}'.format(inFeatures.shape))\n",
    "\n",
    "        \n",
    "#         if type(outFeatures) == int:\n",
    "#             outChannels = outFeatures\n",
    "#         else:\n",
    "#             raise Exception('outFeatures should not be more than 1 dimesnion. It was: {}'.format(outFeatures.shape))\n",
    "\n",
    "        \n",
    "#         super(denseLayer, self).__init__(inChannels, outChannels, kernel, bias=False)\n",
    "        \n",
    "#         # params for the LIF\n",
    "#         self.theta = theta\n",
    "#         self.leak = leak\n",
    "#         self.V_min = V_min\n",
    "        \n",
    "    \n",
    "#     def forward(self, input):\n",
    "#         fc_spikes = F.conv3d(input, \n",
    "#                         self.weight, self.bias, \n",
    "#                         self.stride, self.padding, self.dilation, self.groups)\n",
    "        \n",
    "#         output = LIF(fc_spikes, self.theta, self.leak, self.V_min)\n",
    "        \n",
    "#         return (fc_spikes, *output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for size change\n",
    "1. convLayer correct\n",
    "2. poolLayer correct\n",
    "3. denseLayer correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custmized_layer import convLayer, poolLayer, denseLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test batch size: torch.Size([128, 3, 28, 28, 10])\n",
      "conv batch size: torch.Size([12, 24, 24, 10])\n",
      "pool batch size: torch.Size([3, 14, 14, 10])\n",
      "dense(linear) batch size: torch.Size([2, 1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "test_batch = torch.ones((128,3,28,28,10))\n",
    "\n",
    "slayer_conv = convLayer(3,12,5,theta=0.5)\n",
    "slayer_pool = poolLayer(2,theta=0.5)\n",
    "# the inFeatures of denselayer should be (H,W,C)\n",
    "slayer_dense = denseLayer((28,28,3), 2, theta=0.5)\n",
    "\n",
    "print(\"test batch size:\",test_batch.shape)\n",
    "print(\"conv batch size:\",slayer_conv(test_batch).shape) # should give (128, 12, 24, 24, 10)\n",
    "print(\"pool batch size:\",slayer_pool(test_batch).shape) # should give (128, 3, 14, 14, 10)\n",
    "print(\"dense(linear) batch size:\",slayer_dense(test_batch).shape) # should give (128, 2, 1, 1, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test for correct spikes\n",
    "1. convLayer correct\n",
    "2. poolLayer correct\n",
    "3. denseLayer correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spikes = torch.ones((2,1,4,4,10)) * 0.1\n",
    "\n",
    "slayer_conv = convLayer(1,1,4,theta=0.5)\n",
    "slayer_pool = poolLayer(2,theta=0.5)\n",
    "slayer_dense = denseLayer((4,4,1), 2, theta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]]]])\n",
      "\n",
      "tensor([[[[[0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "          [[0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]],\n",
      "\n",
      "          [[0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "           [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]]]]])\n",
      "\n",
      "tensor([[[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    the layer will return:  1. spikes after corresponding op (conv, pull, linear), \n",
    "                            2. the fire potential \n",
    "                            3. the spikes (whenever the potential larger than theta, it has 1 as entry)\n",
    "\"\"\" \n",
    "print(slayer_conv(test_spikes))\n",
    "print()\n",
    "print(slayer_pool(test_spikes))\n",
    "print()\n",
    "print(slayer_dense(test_spikes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
